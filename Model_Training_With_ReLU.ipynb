{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "The supermarket chain Good Seed would like to explore whether Data Science can help them adhere to alcohol laws by making sure they do not sell alcohol to people underage. I am conducting the evaluation keeping the following in mind:\n",
    "- The shops are equipped with cameras in the checkout area which are triggered when a person is buying alcohol\n",
    "- Computer vision methods can be used to determine age of a person from a photo\n",
    "- The task then is to build and evaluate a model for verifying people's age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "df89053c-55da-4946-b602-c3baf619b53f"
    ]
   },
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv('/datasets/faces/labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>real_age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000000.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000001.jpg</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000002.jpg</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000003.jpg</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000004.jpg</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    file_name  real_age\n",
       "0  000000.jpg         4\n",
       "1  000001.jpg        18\n",
       "2  000002.jpg        80\n",
       "3  000003.jpg        50\n",
       "4  000004.jpg        17"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7591, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  4,  18,  80,  50,  17,  27,  24,  43,  26,  39,  51,   2,   1,\n",
       "         6,   5,  40,  16,  29,  35,  25,  30,  65,  13,  28,  31,  10,\n",
       "        34,  15,   8,  20,  19,  42,  23,  58,  44,   7,  21,  14,  48,\n",
       "        45,  37,  22,  59,  53,   9,  41,  32,  60,  38,  54,  49,  36,\n",
       "        11,  70,  52,  33,  72,  47,  46,  55,  63,  12,  56,   3,  68,\n",
       "        64,  67,  62,  57,  75,  61,  69,  90,  85,  88,  73,  71,  83,\n",
       "        84,  87,  66,  82,  86,  77, 100,  79,  78,  76,  94,  89,  74,\n",
       "        97,  93,  81,  95,  96,  91])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels['real_age'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    7591.000000\n",
       "mean       31.201159\n",
       "std        17.145060\n",
       "min         1.000000\n",
       "25%        20.000000\n",
       "50%        29.000000\n",
       "75%        41.000000\n",
       "max       100.000000\n",
       "Name: real_age, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels['real_age'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAWIklEQVR4nO3df5DU9X3H8eermFgCjWC0OwRIj0zRDkpD5EbpJM0sMdVTM8F0MhbGUYg2l0xwEltmUkwyo43jjG1DbNSU9BIo0FCI9UdgFGMJzY7JTFHBMB7+Codi5YqQBAM5dUxO3/1jP2c2eAd3u3u73n5ej5md++7n++Pz+fA9Xvfdz353P4oIzMwsD7/X7AaYmVnjOPTNzDLi0Dczy4hD38wsIw59M7OMnNTsBpzIaaedFm1tbVXt+9JLLzFhwoT6Nugtzn1ufbn1F9znkdq5c+fPI+L0wda95UO/ra2NHTt2VLVvqVSiWCzWt0Fvce5z68utv+A+j5Sk54Za5+EdM7OMOPTNzDLi0Dczy4hD38wsIw59M7OMOPTNzDLi0Dczy4hD38wsIw59M7OMvOU/kWsj0917hCXL72t4vftuvqThdZrZyPlK38wsIw59M7OMOPTNzDJywtCXNF3SDyU9IelxSZ9P5adK2ippT/o5OZVL0q2SeiQ9JumcimMtTtvvkbR49LplZmaDGc6Vfj+wLCJmAfOApZJmAcuBbRExE9iWngNcBMxMj05gJZT/SADXA+cB5wLXD/yhMDOzxjhh6EfEgYh4NC3/CngSmAosANamzdYCl6blBcC6KNsOTJI0BbgQ2BoRhyPiRWAr0FHPzpiZ2fGN6JZNSW3A+4GHgEJEHEirXgAKaXkq8HzFbvtT2VDlg9XTSflVAoVCgVKpNJJmvqGvr6/qfceqwnhYNru/4fU28985t/OcW3/Bfa6nYYe+pInAXcC1EXFU0hvrIiIkRb0aFRFdQBdAe3t7VDt7TI6z7dy2fhMruhv/8Yt9lxcbXueA3M5zbv0F97mehnX3jqS3UQ789RFxdyo+mIZtSD8PpfJeYHrF7tNS2VDlZmbWIMO5e0fAKuDJiPhaxarNwMAdOIuBTRXlV6a7eOYBR9Iw0APABZImpzdwL0hlZmbWIMMZB/gAcAXQLWlXKvsicDNwh6SrgeeAy9K6LcDFQA/wMvBJgIg4LOlG4JG03Vci4nA9OmFmZsNzwtCPiB8DGmL1+YNsH8DSIY61Glg9kgaamVn9+BO5ZmYZceibmWXEoW9mlhGHvplZRhz6ZmYZceibmWXEoW9mlhGHvplZRhz6ZmYZceibmWXEoW9mlhGHvplZRhz6ZmYZceibmWXEoW9mlhGHvplZRoYzXeJqSYck7a4o+66kXemxb2BGLUltkl6pWPfNin3mSuqW1CPpVlXOrG5mZg0xnOkS1wC3A+sGCiLirwaWJa0AjlRsvzci5gxynJXAp4CHKE+p2AHcP+IWm5lZ1U54pR8RDwKDzmWbrtYvAzYc7xiSpgDvjIjtaTrFdcClI26tmZnVZDhX+sfz58DBiNhTUTZD0k+Ao8CXI+JHwFRgf8U2+1PZoCR1Ap0AhUKBUqlUVeP6+vqq3nesKoyHZbP7G15vM/+dczvPufUX3Od6qjX0F/G7V/kHgPdExC8kzQW+J+mskR40IrqALoD29vYoFotVNa5UKlHtvmPVbes3saK71tM6cvsuLza8zgG5nefc+gvucz1VnQ6STgL+Epg7UBYRrwKvpuWdkvYCZwC9wLSK3aelMjMza6Babtn8CPBURLwxbCPpdEnj0vJ7gZnAMxFxADgqaV56H+BKYFMNdZuZWRWGc8vmBuB/gDMl7Zd0dVq1kDe/gfsh4LF0C+edwGciYuBN4M8C3wZ6gL34zh0zs4Y74fBORCwaonzJIGV3AXcNsf0O4OwRts/MzOrIn8g1M8uIQ9/MLCMOfTOzjDj0zcwy4tA3M8uIQ9/MLCMOfTOzjDj0zcwy4tA3M8uIQ9/MLCMOfTOzjDj0zcwy4tA3M8tI46dYspbUtvy+ptW9pmNC0+o2G2t8pW9mlhGHvplZRoYzc9ZqSYck7a4ou0FSr6Rd6XFxxbrrJPVIelrShRXlHamsR9Ly+nfFzMxOZDhX+muAjkHKb4mIOemxBUDSLMrTKJ6V9vkXSePSvLnfAC4CZgGL0rZmZtZAw5ku8UFJbcM83gJgY0S8CjwrqQc4N63riYhnACRtTNs+MfImm5lZtWq5e+caSVcCO4BlEfEiMBXYXrHN/lQG8Pwx5ecNdWBJnUAnQKFQoFQqVdXAvr6+qvcdqwrjYdns/mY3o6FyO8+59Rfc53qqNvRXAjcCkX6uAK6qV6MiogvoAmhvb49isVjVcUqlEtXuO1bdtn4TK7rzuhN3TceErM5zjr/X7nP9VJUOEXFwYFnSt4B709NeYHrFptNSGccpNzOzBqnqlk1JUyqefhwYuLNnM7BQ0smSZgAzgYeBR4CZkmZIejvlN3s3V99sMzOrxgmv9CVtAIrAaZL2A9cDRUlzKA/v7AM+DRARj0u6g/IbtP3A0oh4LR3nGuABYBywOiIer3dnzMzs+IZz986iQYpXHWf7m4CbBinfAmwZUevMzKyu/IlcM7OMOPTNzDLi0Dczy4hD38wsIw59M7OMOPTNzDLi0Dczy4hD38wsIw59M7OMOPTNzDLi0Dczy4hD38wsIw59M7OMOPTNzDLi0Dczy4hD38wsIycMfUmrJR2StLui7J8kPSXpMUn3SJqUytskvSJpV3p8s2KfuZK6JfVIulWSRqVHZmY2pOFc6a8BOo4p2wqcHRF/CvwUuK5i3d6ImJMen6koXwl8ivK8uTMHOaaZmY2yE4Z+RDwIHD6m7L8ioj893Q5MO94x0kTq74yI7RERwDrg0qpabGZmVTvhHLnDcBXw3YrnMyT9BDgKfDkifgRMBfZXbLM/lQ1KUifQCVAoFCiVSlU1rK+vr+p9x6rCeFg2u//EG7aQ3M5zbv0F97meagp9SV8C+oH1qegA8J6I+IWkucD3JJ010uNGRBfQBdDe3h7FYrGq9pVKJardd6y6bf0mVnTX42/52LGmY0JW5znH32v3uX6qTgdJS4CPAuenIRsi4lXg1bS8U9Je4Aygl98dApqWyszMrIGqumVTUgfwBeBjEfFyRfnpksal5fdSfsP2mYg4AByVNC/dtXMlsKnm1puZ2Yic8Epf0gagCJwmaT9wPeW7dU4GtqY7L7enO3U+BHxF0m+A14HPRMTAm8CfpXwn0Hjg/vRoSW3L72ta3ctmN61qMxsDThj6EbFokOJVQ2x7F3DXEOt2AGePqHVmZlZX/kSumVlGHPpmZhlx6JuZZcShb2aWEYe+mVlGHPpmZhlx6JuZZcShb2aWEYe+mVlGHPpmZhlx6JuZZcShb2aWEYe+mVlGHPpmZhlx6JuZZcShb2aWkWGFvqTVkg5J2l1RdqqkrZL2pJ+TU7kk3SqpR9Jjks6p2Gdx2n6PpMX1746ZmR3PcK/01wAdx5QtB7ZFxExgW3oOcBHluXFnAp3ASij/kaA81eJ5wLnA9QN/KMzMrDGGFfoR8SBw+JjiBcDatLwWuLSifF2UbQcmSZoCXAhsjYjDEfEisJU3/yExM7NRdMI5co+jEBEH0vILQCEtTwWer9hufyobqvxNJHVSfpVAoVCgVCpV1cC+vr6q963Fstn9Da9zQGF8c+tvhmad52bJrb/gPtdTLaH/hogISVGPY6XjdQFdAO3t7VEsFqs6TqlUotp9a7Fk+X0Nr3PAstn9rOiuy2kdM9Z0TGjKeW6WZv1eN5P7XD+13L1zMA3bkH4eSuW9wPSK7aalsqHKzcysQWoJ/c3AwB04i4FNFeVXprt45gFH0jDQA8AFkianN3AvSGVmZtYgwxoHkLQBKAKnSdpP+S6cm4E7JF0NPAdcljbfAlwM9AAvA58EiIjDkm4EHknbfSUijn1z2MzMRtGwQj8iFg2x6vxBtg1g6RDHWQ2sHnbrzMysrvJ6x89aUnfvkaa8eb7v5ksaXqdZrfw1DGZmGXHom5llxKFvZpYRh76ZWUYc+mZmGXHom5llxKFvZpYRh76ZWUYc+mZmGXHom5llxKFvZpYRh76ZWUYc+mZmGXHom5llxKFvZpaRqkNf0pmSdlU8jkq6VtINknoryi+u2Oc6ST2SnpZ0YX26YGZmw1X1JCoR8TQwB0DSOMqTnN9DeXrEWyLiq5XbS5oFLATOAt4N/EDSGRHxWrVtMDOzkanX8M75wN6IeO442ywANkbEqxHxLOU5dM+tU/1mZjYMKk9pW+NBpNXAoxFxu6QbgCXAUWAHsCwiXpR0O7A9Ir6T9lkF3B8Rdw5yvE6gE6BQKMzduHFjVe3q6+tj4sSJVe1bi+7eIw2vc0BhPBx8pWnVN0Wz+jx76imNr5Tm/V43k/s8MvPnz98ZEe2Dras59CW9Hfg/4KyIOCipAPwcCOBGYEpEXDWS0K/U3t4eO3bsqKptpVKJYrFY1b61aGvCfK0Dls3uZ0V3XlMfN6vPzZojt1m/183kPo+MpCFDvx7DOxdRvso/CBARByPitYh4HfgWvx3C6QWmV+w3LZWZmVmD1CP0FwEbBp5ImlKx7uPA7rS8GVgo6WRJM4CZwMN1qN/MzIapptfEkiYAfwF8uqL4HyXNoTy8s29gXUQ8LukO4AmgH1jqO3fMzBqrptCPiJeAdx1TdsVxtr8JuKmWOs3MrHr+RK6ZWUYc+mZmGXHom5llpKVv6O7uPcKSJt4zb2b2VuMrfTOzjDj0zcwy4tA3M8tIS4/pm42mZn3H0pqOCU2p11qDr/TNzDLi0Dczy4hD38wsIw59M7OMOPTNzDLi0Dczy4hD38wsIw59M7OM1Bz6kvZJ6pa0S9KOVHaqpK2S9qSfk1O5JN0qqUfSY5LOqbV+MzMbvnpd6c+PiDkVs68vB7ZFxExgW3oO5UnUZ6ZHJ7CyTvWbmdkwjNbwzgJgbVpeC1xaUb4uyrYDk46ZSN3MzEaRIqK2A0jPAi9Sngj9XyOiS9IvI2JSWi/gxYiYJOle4OaI+HFatw34u4jYccwxOym/EqBQKMzduHFjVW07dPgIB1+psmNjVGE87nOLm3HKOCZOnNjsZjRUX1+f+zwC8+fP31kx8vI76vGFax+MiF5JfwhslfRU5cqICEkj+ssSEV1AF0B7e3sUi8WqGnbb+k2s6M7rO+WWze53n1vcmo4JVPt/YqwqlUruc53UPLwTEb3p5yHgHuBc4ODAsE36eSht3gtMr9h9WiozM7MGqCn0JU2Q9AcDy8AFwG5gM7A4bbYY2JSWNwNXprt45gFHIuJALW0wM7Phq/U1cQG4pzxsz0nAf0TE9yU9Atwh6WrgOeCytP0W4GKgB3gZ+GSN9ZuZ2QjUFPoR8QzwvkHKfwGcP0h5AEtrqdPMzKrnT+SamWXEoW9mlhGHvplZRhz6ZmYZceibmWXEoW9mlhGHvplZRhz6ZmYZceibmWXEoW9mlhGHvplZRhz6ZmYZceibmWXEoW9mlhGHvplZRhz6ZmYZqXoSFUnTgXWUZ88KoCsivi7pBuBTwM/Spl+MiC1pn+uAq4HXgM9FxAM1tN0sS929R1iy/L6m1L3v5kuaUq/VTy0zZ/UDyyLi0TRP7k5JW9O6WyLiq5UbS5oFLATOAt4N/EDSGRHxWg1tMDOzEah6eCciDkTEo2n5V8CTwNTj7LIA2BgRr0bEs5TnyT232vrNzGzkVJ62tsaDSG3Ag8DZwN8CS4CjwA7KrwZelHQ7sD0ivpP2WQXcHxF3DnK8TqAToFAozN24cWNV7Tp0+AgHX6lq1zGrMB73ucU1s7+zp57SlHr7+vqYOHFiU+pullr6PH/+/J0R0T7YupomRgeQNBG4C7g2Io5KWgncSHmc/0ZgBXDVSI4ZEV1AF0B7e3sUi8Wq2nbb+k2s6K65i2PKstn97nOLa2Z/911ebEq9pVKJanNgrBqtPtd0946kt1EO/PURcTdARByMiNci4nXgW/x2CKcXmF6x+7RUZmZmDVJ16EsSsAp4MiK+VlE+pWKzjwO70/JmYKGkkyXNAGYCD1dbv5mZjVwtrxE/AFwBdEvalcq+CCySNIfy8M4+4NMAEfG4pDuAJyjf+bPUd+6YmTVW1aEfET8GNMiqLcfZ5ybgpmrrNDOz2vgTuWZmGXHom5llxKFvZpYRh76ZWUYc+mZmGXHom5llJJ/PrptZzdqa9JXOazomNKXeVuQrfTOzjDj0zcwy4tA3M8uIQ9/MLCN+I9fM3vI8L3D9+ErfzCwjDn0zs4w49M3MMuIxfTOz42i1D6Q1/EpfUoekpyX1SFre6PrNzHLW0NCXNA74BnARMIvy1IqzGtkGM7OcNfpK/1ygJyKeiYhfAxuBBQ1ug5lZthQRjatM+gTQERF/nZ5fAZwXEdccs10n0Jmengk8XWWVpwE/r3Lfscp9bn259Rfc55H6o4g4fbAVb8k3ciOiC+iq9TiSdkREex2aNGa4z60vt/6C+1xPjR7e6QWmVzyflsrMzKwBGh36jwAzJc2Q9HZgIbC5wW0wM8tWQ4d3IqJf0jXAA8A4YHVEPD6KVdY8RDQGuc+tL7f+gvtcNw19I9fMzJrLX8NgZpYRh76ZWUZaMvRz+KoHSdMl/VDSE5Iel/T5VH6qpK2S9qSfk5vd1nqTNE7STyTdm57PkPRQOt/fTTcJtAxJkyTdKekpSU9K+rNWP8+S/ib9Xu+WtEHS77faeZa0WtIhSbsrygY9ryq7NfX9MUnnVFtvy4V+Rl/10A8si4hZwDxgaerncmBbRMwEtqXnrebzwJMVz/8BuCUi/hh4Ebi6Ka0aPV8Hvh8RfwK8j3LfW/Y8S5oKfA5oj4izKd/0sZDWO89rgI5jyoY6rxcBM9OjE1hZbaUtF/pk8lUPEXEgIh5Ny7+iHARTKfd1bdpsLXBpUxo4SiRNAy4Bvp2eC/gwcGfapKX6LOkU4EPAKoCI+HVE/JIWP8+U7ywcL+kk4B3AAVrsPEfEg8DhY4qHOq8LgHVRth2YJGlKNfW2YuhPBZ6veL4/lbUsSW3A+4GHgEJEHEirXgAKzWrXKPln4AvA6+n5u4BfRkR/et5q53sG8DPg39KQ1rclTaCFz3NE9AJfBf6XctgfAXbS2ud5wFDntW651oqhnxVJE4G7gGsj4mjluijfj9sy9+RK+ihwKCJ2NrstDXQScA6wMiLeD7zEMUM5LXieJ1O+sp0BvBuYwJuHQVreaJ3XVgz9bL7qQdLbKAf++oi4OxUfHHjZl34ealb7RsEHgI9J2kd52O7DlMe7J6VhAGi9870f2B8RD6Xnd1L+I9DK5/kjwLMR8bOI+A1wN+Vz38rnecBQ57VuudaKoZ/FVz2ksexVwJMR8bWKVZuBxWl5MbCp0W0bLRFxXURMi4g2yuf1vyPicuCHwCfSZq3W5xeA5yWdmYrOB56ghc8z5WGdeZLekX7PB/rcsue5wlDndTNwZbqLZx5wpGIYaGQiouUewMXAT4G9wJea3Z5R6uMHKb/0ewzYlR4XUx7j3gbsAX4AnNrsto5S/4vAvWn5vcDDQA/wn8DJzW5fnfs6B9iRzvX3gMmtfp6BvweeAnYD/w6c3GrnGdhA+T2L31B+RXf1UOcVEOW7EvcC3ZTvbKqqXn8Ng5lZRlpxeMfMzIbg0Dczy4hD38wsIw59M7OMOPTNzDLi0Dczy4hD38wsI/8P6ZFPr+4CaJ0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "labels['real_age'].hist(bins=10, range=(0, 100))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There are 7591 image files\n",
    "- The age of people ranges from 1 -100 years old\n",
    "- The average age is 29 years old\n",
    "- Most of the people are aged between 20 and 30 years old.\n",
    "- There are fewer people with the age 60 and above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the necessary functions to train your model on the GPU platform and build a single script containing all of them along with the initialization section.\n",
    "\n",
    "To make this task easier, you can define them in this notebook and run a ready code in the next section to automatically compose the script.\n",
    "\n",
    "The definitions below will be checked by project reviewers as well, so that they can understand how you built the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.resnet import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, Flatten\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train(path):\n",
    "    labels = pd.read_csv(path + 'labels.csv')\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        validation_split=0.25,\n",
    "        horizontal_flip=True,\n",
    "        rescale=1./255)\n",
    "    train_gen_flow = train_datagen.flow_from_dataframe(\n",
    "        dataframe=labels,\n",
    "        directory=path + 'final_files/',\n",
    "        x_col='file_name',\n",
    "        y_col='real_age',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=16,\n",
    "        class_mode='raw',\n",
    "        subset='training',\n",
    "        seed=12345)\n",
    " \n",
    "    return train_gen_flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test(path):\n",
    "    labels = pd.read_csv(path + 'labels.csv')\n",
    "    test_datagen = ImageDataGenerator(\n",
    "        validation_split=0.25,\n",
    "        rescale=1./255)\n",
    "    test_gen_flow = test_datagen.flow_from_dataframe(\n",
    "        dataframe=labels,\n",
    "        directory=path + 'final_files/',\n",
    "        x_col='file_name',\n",
    "        y_col='real_age',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=16,\n",
    "        class_mode='raw',\n",
    "        subset='validation',\n",
    "        seed=12345)\n",
    " \n",
    "    return test_gen_flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape):\n",
    "    backbone = ResNet50(weights='imagenet', \n",
    "                        input_shape=input_shape,\n",
    "                        include_top=False)\n",
    " \n",
    "    model = Sequential()\n",
    "    model.add(backbone)\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dense(1, activation='relu'))\n",
    " \n",
    "    optimizer = Adam(lr=0.0005)\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
    " \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_data, test_data, batch_size=None, epochs=20,\n",
    "                steps_per_epoch=None, validation_steps=None):\n",
    " \n",
    "    if steps_per_epoch is None:\n",
    "        steps_per_epoch = len(train_data)\n",
    "    if validation_steps is None:\n",
    "        validation_steps = len(test_data)\n",
    " \n",
    "    model.fit(train_data, \n",
    "              validation_data=test_data,\n",
    "              batch_size=batch_size, epochs=epochs,\n",
    "              steps_per_epoch=steps_per_epoch,\n",
    "              validation_steps=validation_steps,\n",
    "              verbose=2)\n",
    " \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the Script to Run on the GPU Platform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given you've defined the necessary functions you can compose a script for the GPU platform, download it via the \"File|Open...\" menu, and to upload it later for running on the GPU platform.\n",
    "\n",
    "N.B.: The script should include the initialization section as well. An example of this is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare a script to run on the GPU platform\n",
    "\n",
    "init_str = \"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.resnet import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\"\"\"\n",
    "\n",
    "import inspect\n",
    "\n",
    "with open('run_model_on_gpu.py', 'w') as f:\n",
    "    \n",
    "    f.write(init_str)\n",
    "    f.write('\\n\\n')\n",
    "        \n",
    "    for fn_name in [load_train, load_test, create_model, train_model]:\n",
    "        \n",
    "        src = inspect.getsource(fn_name)\n",
    "        f.write(src)\n",
    "        f.write('\\n\\n')\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Placing the output from the GPU platform as an Markdown cell here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2022-05-08 23:00:41.671588: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer.so.6\n",
    "2022-05-08 23:00:41.673283: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer_plugin.so.6\n",
    "Using TensorFlow backend.\n",
    "Found 5694 validated image filenames.\n",
    "Found 1897 validated image filenames.\n",
    "2022-05-08 23:00:42.894304: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
    "2022-05-08 23:00:43.582241: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \n",
    "pciBusID: 0000:8b:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\n",
    "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
    "2022-05-08 23:00:43.582328: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
    "2022-05-08 23:00:43.582361: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
    "2022-05-08 23:00:43.584295: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
    "2022-05-08 23:00:43.584690: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
    "2022-05-08 23:00:43.587076: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
    "2022-05-08 23:00:43.588245: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
    "2022-05-08 23:00:43.588320: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
    "2022-05-08 23:00:43.592613: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\n",
    "2022-05-08 23:00:43.592970: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
    "2022-05-08 23:00:43.599839: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2099990000 Hz\n",
    "2022-05-08 23:00:43.600424: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3970f30 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
    "2022-05-08 23:00:43.600454: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
    "2022-05-08 23:00:43.743401: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x46b84b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
    "2022-05-08 23:00:43.743442: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
    "2022-05-08 23:00:43.745857: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \n",
    "pciBusID: 0000:8b:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\n",
    "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
    "2022-05-08 23:00:43.745925: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
    "2022-05-08 23:00:43.745935: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
    "2022-05-08 23:00:43.745962: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
    "2022-05-08 23:00:43.745972: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
    "2022-05-08 23:00:43.745981: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
    "2022-05-08 23:00:43.745989: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
    "2022-05-08 23:00:43.745997: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
    "2022-05-08 23:00:43.750506: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\n",
    "2022-05-08 23:00:43.750589: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
    "2022-05-08 23:00:44.063725: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
    "2022-05-08 23:00:44.063778: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 \n",
    "2022-05-08 23:00:44.063787: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N \n",
    "2022-05-08 23:00:44.068598: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30509 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:8b:00.0, compute capability: 7.0)\n",
    "<class 'tensorflow.python.keras.engine.sequential.Sequential'>\n",
    "WARNING:tensorflow:sample_weight modes were coerced from\n",
    "  ...\n",
    "    to  \n",
    "  ['...']\n",
    "WARNING:tensorflow:sample_weight modes were coerced from\n",
    "  ...\n",
    "    to  \n",
    "  ['...']\n",
    "Train for 356 steps, validate for 119 steps\n",
    "Epoch 1/20\n",
    "2022-05-08 23:00:54.906195: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
    "2022-05-08 23:00:55.231224: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
    "356/356 - 98s - loss: 207.6220 - mae: 10.8524 - val_loss: 323.3346 - val_mae: 13.3272\n",
    "Epoch 2/20\n",
    "356/356 - 38s - loss: 136.3556 - mae: 8.9599 - val_loss: 278.4501 - val_mae: 13.5151\n",
    "Epoch 3/20\n",
    "356/356 - 38s - loss: 110.3684 - mae: 8.0395 - val_loss: 163.0583 - val_mae: 9.2809\n",
    "Epoch 4/20\n",
    "356/356 - 38s - loss: 93.5072 - mae: 7.3856 - val_loss: 206.2468 - val_mae: 10.3820\n",
    "Epoch 5/20\n",
    "356/356 - 37s - loss: 80.6262 - mae: 6.8823 - val_loss: 151.8503 - val_mae: 9.6981\n",
    "Epoch 6/20\n",
    "356/356 - 38s - loss: 63.5863 - mae: 6.0973 - val_loss: 165.6288 - val_mae: 9.8098\n",
    "Epoch 7/20\n",
    "356/356 - 38s - loss: 53.7330 - mae: 5.6430 - val_loss: 122.0895 - val_mae: 8.3484\n",
    "Epoch 8/20\n",
    "356/356 - 37s - loss: 45.0534 - mae: 5.1247 - val_loss: 90.8101 - val_mae: 7.1414\n",
    "Epoch 9/20\n",
    "356/356 - 38s - loss: 42.9235 - mae: 4.9944 - val_loss: 162.1831 - val_mae: 9.9839\n",
    "Epoch 10/20\n",
    "356/356 - 38s - loss: 36.1889 - mae: 4.6620 - val_loss: 118.7158 - val_mae: 8.0478\n",
    "Epoch 11/20\n",
    "356/356 - 37s - loss: 29.1866 - mae: 4.2138 - val_loss: 106.7834 - val_mae: 7.5927\n",
    "Epoch 12/20\n",
    "356/356 - 38s - loss: 27.5572 - mae: 4.0434 - val_loss: 104.3532 - val_mae: 7.8868\n",
    "Epoch 13/20\n",
    "356/356 - 38s - loss: 26.1322 - mae: 3.9356 - val_loss: 88.4752 - val_mae: 7.0884\n",
    "Epoch 14/20\n",
    "356/356 - 38s - loss: 25.7657 - mae: 3.9169 - val_loss: 94.0407 - val_mae: 7.4884\n",
    "Epoch 15/20\n",
    "356/356 - 38s - loss: 22.8202 - mae: 3.6662 - val_loss: 84.8546 - val_mae: 6.8775\n",
    "Epoch 16/20\n",
    "356/356 - 38s - loss: 20.9390 - mae: 3.5406 - val_loss: 83.4330 - val_mae: 6.7209\n",
    "Epoch 17/20\n",
    "356/356 - 38s - loss: 19.6756 - mae: 3.4232 - val_loss: 78.9828 - val_mae: 6.5279\n",
    "Epoch 18/20\n",
    "356/356 - 37s - loss: 17.9286 - mae: 3.2583 - val_loss: 79.4942 - val_mae: 6.6038\n",
    "Epoch 19/20\n",
    "356/356 - 38s - loss: 17.2759 - mae: 3.1923 - val_loss: 82.4948 - val_mae: 6.7939\n",
    "Epoch 20/20\n",
    "356/356 - 38s - loss: 17.4754 - mae: 3.2148 - val_loss: 80.1763 - val_mae: 6.8733\n",
    "WARNING:tensorflow:sample_weight modes were coerced from\n",
    "  ...\n",
    "    to  \n",
    "  ['...']\n",
    "119/119 - 9s - loss: 80.1763 - mae: 6.8733\n",
    "Test MAE: 6.8733\n",
    "2022-05-08 23:00:41.671588: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer.so.6\n",
    "2022-05-08 23:00:41.673283: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer_plugin.so.6\n",
    "Using TensorFlow backend.\n",
    "Found 5694 validated image filenames.\n",
    "Found 1897 validated image filenames.\n",
    "2022-05-08 23:00:42.894304: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
    "2022-05-08 23:00:43.582241: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \n",
    "pciBusID: 0000:8b:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\n",
    "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
    "2022-05-08 23:00:43.582328: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
    "2022-05-08 23:00:43.582361: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
    "2022-05-08 23:00:43.584295: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
    "2022-05-08 23:00:43.584690: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
    "2022-05-08 23:00:43.587076: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
    "2022-05-08 23:00:43.588245: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
    "2022-05-08 23:00:43.588320: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
    "2022-05-08 23:00:43.592613: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\n",
    "2022-05-08 23:00:43.592970: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
    "2022-05-08 23:00:43.599839: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2099990000 Hz\n",
    "2022-05-08 23:00:43.600424: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3970f30 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
    "2022-05-08 23:00:43.600454: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
    "2022-05-08 23:00:43.743401: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x46b84b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
    "2022-05-08 23:00:43.743442: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
    "2022-05-08 23:00:43.745857: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \n",
    "pciBusID: 0000:8b:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\n",
    "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
    "2022-05-08 23:00:43.745925: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
    "2022-05-08 23:00:43.745935: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
    "2022-05-08 23:00:43.745962: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
    "2022-05-08 23:00:43.745972: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
    "2022-05-08 23:00:43.745981: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
    "2022-05-08 23:00:43.745989: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
    "2022-05-08 23:00:43.745997: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
    "2022-05-08 23:00:43.750506: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\n",
    "2022-05-08 23:00:43.750589: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
    "2022-05-08 23:00:44.063725: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
    "2022-05-08 23:00:44.063778: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 \n",
    "2022-05-08 23:00:44.063787: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N \n",
    "2022-05-08 23:00:44.068598: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30509 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:8b:00.0, compute capability: 7.0)\n",
    "<class 'tensorflow.python.keras.engine.sequential.Sequential'>\n",
    "WARNING:tensorflow:sample_weight modes were coerced from\n",
    "  ...\n",
    "    to  \n",
    "  ['...']\n",
    "WARNING:tensorflow:sample_weight modes were coerced from\n",
    "  ...\n",
    "    to  \n",
    "  ['...']\n",
    "Train for 356 steps, validate for 119 steps\n",
    "Epoch 1/20\n",
    "2022-05-08 23:00:54.906195: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
    "2022-05-08 23:00:55.231224: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
    "356/356 - 98s - loss: 207.6220 - mae: 10.8524 - val_loss: 323.3346 - val_mae: 13.3272\n",
    "Epoch 2/20\n",
    "356/356 - 38s - loss: 136.3556 - mae: 8.9599 - val_loss: 278.4501 - val_mae: 13.5151\n",
    "Epoch 3/20\n",
    "356/356 - 38s - loss: 110.3684 - mae: 8.0395 - val_loss: 163.0583 - val_mae: 9.2809\n",
    "Epoch 4/20\n",
    "356/356 - 38s - loss: 93.5072 - mae: 7.3856 - val_loss: 206.2468 - val_mae: 10.3820\n",
    "Epoch 5/20\n",
    "356/356 - 37s - loss: 80.6262 - mae: 6.8823 - val_loss: 151.8503 - val_mae: 9.6981\n",
    "Epoch 6/20\n",
    "356/356 - 38s - loss: 63.5863 - mae: 6.0973 - val_loss: 165.6288 - val_mae: 9.8098\n",
    "Epoch 7/20\n",
    "356/356 - 38s - loss: 53.7330 - mae: 5.6430 - val_loss: 122.0895 - val_mae: 8.3484\n",
    "Epoch 8/20\n",
    "356/356 - 37s - loss: 45.0534 - mae: 5.1247 - val_loss: 90.8101 - val_mae: 7.1414\n",
    "Epoch 9/20\n",
    "356/356 - 38s - loss: 42.9235 - mae: 4.9944 - val_loss: 162.1831 - val_mae: 9.9839\n",
    "Epoch 10/20\n",
    "356/356 - 38s - loss: 36.1889 - mae: 4.6620 - val_loss: 118.7158 - val_mae: 8.0478\n",
    "Epoch 11/20\n",
    "356/356 - 37s - loss: 29.1866 - mae: 4.2138 - val_loss: 106.7834 - val_mae: 7.5927\n",
    "Epoch 12/20\n",
    "356/356 - 38s - loss: 27.5572 - mae: 4.0434 - val_loss: 104.3532 - val_mae: 7.8868\n",
    "Epoch 13/20\n",
    "356/356 - 38s - loss: 26.1322 - mae: 3.9356 - val_loss: 88.4752 - val_mae: 7.0884\n",
    "Epoch 14/20\n",
    "356/356 - 38s - loss: 25.7657 - mae: 3.9169 - val_loss: 94.0407 - val_mae: 7.4884\n",
    "Epoch 15/20\n",
    "356/356 - 38s - loss: 22.8202 - mae: 3.6662 - val_loss: 84.8546 - val_mae: 6.8775\n",
    "Epoch 16/20\n",
    "356/356 - 38s - loss: 20.9390 - mae: 3.5406 - val_loss: 83.4330 - val_mae: 6.7209\n",
    "Epoch 17/20\n",
    "356/356 - 38s - loss: 19.6756 - mae: 3.4232 - val_loss: 78.9828 - val_mae: 6.5279\n",
    "Epoch 18/20\n",
    "356/356 - 37s - loss: 17.9286 - mae: 3.2583 - val_loss: 79.4942 - val_mae: 6.6038\n",
    "Epoch 19/20\n",
    "356/356 - 38s - loss: 17.2759 - mae: 3.1923 - val_loss: 82.4948 - val_mae: 6.7939\n",
    "Epoch 20/20\n",
    "356/356 - 38s - loss: 17.4754 - mae: 3.2148 - val_loss: 80.1763 - val_mae: 6.8733\n",
    "WARNING:tensorflow:sample_weight modes were coerced from\n",
    "  ...\n",
    "    to  \n",
    "  ['...']\n",
    "119/119 - 9s - loss: 80.1763 - mae: 6.8733\n",
    "Test MAE: 6.8733\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There are 7591 image files\n",
    "- The age of people ranges from 1 -100 years old\n",
    "- The average age is 29 years old\n",
    "- Most of the people are aged between 20 and 30 years old.\n",
    "- There are fewer people with the age 60 and above\n",
    "- We created the model that predicts the age of the customer by scanning the image.\n",
    "- The ResNet Model has MAE score of 6.87 in the test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset was downloaded from [ChaLearn Looking at People](https://chalearnlap.cvc.uab.cat/dataset/26/description/)"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 460,
    "start_time": "2022-05-03T02:23:28.687Z"
   },
   {
    "duration": 12,
    "start_time": "2022-05-03T02:23:36.991Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-03T02:23:54.908Z"
   },
   {
    "duration": 58,
    "start_time": "2022-05-03T02:24:27.718Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-03T02:24:39.585Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-03T02:24:48.374Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-03T02:24:58.909Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-03T02:25:10.376Z"
   },
   {
    "duration": 8,
    "start_time": "2022-05-03T02:25:53.490Z"
   },
   {
    "duration": 8,
    "start_time": "2022-05-03T02:25:57.827Z"
   },
   {
    "duration": 9,
    "start_time": "2022-05-03T02:26:00.644Z"
   },
   {
    "duration": 8,
    "start_time": "2022-05-03T02:26:06.128Z"
   },
   {
    "duration": 8,
    "start_time": "2022-05-03T02:27:59.495Z"
   },
   {
    "duration": 19,
    "start_time": "2022-05-03T02:29:44.219Z"
   },
   {
    "duration": 128976,
    "start_time": "2022-05-03T02:29:55.439Z"
   },
   {
    "duration": 39059,
    "start_time": "2022-05-03T02:32:10.801Z"
   },
   {
    "duration": 624,
    "start_time": "2022-05-03T02:33:11.499Z"
   },
   {
    "duration": 107,
    "start_time": "2022-05-03T02:33:29.687Z"
   },
   {
    "duration": 141,
    "start_time": "2022-05-03T02:33:33.029Z"
   },
   {
    "duration": 9,
    "start_time": "2022-05-03T02:35:45.425Z"
   },
   {
    "duration": 176,
    "start_time": "2022-05-03T02:36:49.246Z"
   },
   {
    "duration": 79191,
    "start_time": "2022-05-03T02:36:53.723Z"
   },
   {
    "duration": 153,
    "start_time": "2022-05-03T02:39:48.987Z"
   },
   {
    "duration": 122,
    "start_time": "2022-05-03T02:40:51.555Z"
   },
   {
    "duration": 13,
    "start_time": "2022-05-03T02:41:44.715Z"
   },
   {
    "duration": 116,
    "start_time": "2022-05-03T02:41:53.702Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-03T02:44:05.688Z"
   },
   {
    "duration": 19,
    "start_time": "2022-05-03T02:44:11.049Z"
   },
   {
    "duration": 7,
    "start_time": "2022-05-03T02:44:11.887Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-03T02:44:12.267Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-03T02:44:12.745Z"
   },
   {
    "duration": 9,
    "start_time": "2022-05-03T02:44:15.007Z"
   },
   {
    "duration": 121,
    "start_time": "2022-05-03T02:44:16.053Z"
   },
   {
    "duration": 123,
    "start_time": "2022-05-03T02:46:53.227Z"
   },
   {
    "duration": 140,
    "start_time": "2022-05-03T02:47:23.281Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-03T02:47:32.185Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-03T02:48:30.537Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-03T02:48:46.335Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-03T02:49:22.214Z"
   },
   {
    "duration": 97,
    "start_time": "2022-05-03T02:49:28.025Z"
   },
   {
    "duration": 91,
    "start_time": "2022-05-03T02:50:07.115Z"
   },
   {
    "duration": 162,
    "start_time": "2022-05-03T02:57:11.854Z"
   },
   {
    "duration": 15,
    "start_time": "2022-05-03T02:59:35.328Z"
   },
   {
    "duration": 33,
    "start_time": "2022-05-03T03:01:11.526Z"
   },
   {
    "duration": 101,
    "start_time": "2022-05-03T03:01:23.971Z"
   },
   {
    "duration": 112,
    "start_time": "2022-05-03T03:01:48.477Z"
   },
   {
    "duration": 132,
    "start_time": "2022-05-03T03:05:35.017Z"
   },
   {
    "duration": 48,
    "start_time": "2022-05-05T02:26:23.614Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-05T02:26:29.522Z"
   },
   {
    "duration": 8,
    "start_time": "2022-05-05T02:26:30.304Z"
   },
   {
    "duration": 196026,
    "start_time": "2022-05-05T02:26:34.955Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-05T02:29:50.983Z"
   },
   {
    "duration": 157701,
    "start_time": "2022-05-05T02:29:50.989Z"
   },
   {
    "duration": 71203,
    "start_time": "2022-05-05T02:38:12.408Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-05T02:39:23.614Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-05T02:39:27.196Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-05T02:41:37.642Z"
   },
   {
    "duration": 200,
    "start_time": "2022-05-05T02:42:00.177Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-05T02:42:11.420Z"
   },
   {
    "duration": 28,
    "start_time": "2022-05-05T02:42:15.766Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-05T02:42:31.389Z"
   },
   {
    "duration": 85713,
    "start_time": "2022-05-05T02:42:36.042Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-05T02:44:24.937Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-05T02:45:47.567Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-05T02:46:04.799Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-05T02:46:07.349Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-05T03:06:36.404Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-05T03:06:36.875Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-05T03:06:37.244Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-05T03:06:37.651Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-05T03:06:38.130Z"
   },
   {
    "duration": 133,
    "start_time": "2022-05-05T03:06:44.308Z"
   },
   {
    "duration": 82659,
    "start_time": "2022-05-09T00:42:18.642Z"
   },
   {
    "duration": 49,
    "start_time": "2022-05-09T00:43:41.304Z"
   },
   {
    "duration": 15,
    "start_time": "2022-05-09T00:43:41.355Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-09T00:43:41.373Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-09T00:43:41.380Z"
   },
   {
    "duration": 13,
    "start_time": "2022-05-09T00:43:41.388Z"
   },
   {
    "duration": 257,
    "start_time": "2022-05-09T00:43:41.403Z"
   },
   {
    "duration": 7,
    "start_time": "2022-05-09T00:43:41.662Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-09T00:43:41.671Z"
   },
   {
    "duration": 8,
    "start_time": "2022-05-09T00:43:41.680Z"
   },
   {
    "duration": 7,
    "start_time": "2022-05-09T00:43:41.689Z"
   },
   {
    "duration": 9,
    "start_time": "2022-05-09T00:43:41.698Z"
   },
   {
    "duration": 115,
    "start_time": "2022-05-09T00:43:41.709Z"
   },
   {
    "duration": 90,
    "start_time": "2022-05-09T00:46:09.517Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
